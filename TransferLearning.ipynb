{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOsSUBOKzx5f9WYr4Wjbiqd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shaakib99/Machine-Learning/blob/master/TransferLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XiCk4zQ4BeUb",
        "outputId": "a4ae0e41-624c-4a77-cebc-d5f94eb5dda5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "\n",
        "# Download dataset and make train & test dataset\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "path_to_zip = tf.keras.utils.get_file('cats_and_dogs.zip', origin=_URL, extract=True)\n",
        "PATH = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n",
        "\n",
        "train_dir = os.path.join(PATH, 'train')\n",
        "validation_dir = os.path.join(PATH, 'validation')\n",
        "\n",
        "BATCH_SIZE = 32 # Batch size \n",
        "IMG_SIZE = (160,160)\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    shuffle = True,\n",
        "    image_size = IMG_SIZE,\n",
        "    batch_size = BATCH_SIZE\n",
        ")\n",
        "validation_dataset =  image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    shuffle = True,\n",
        "    image_size = IMG_SIZE,\n",
        "    batch_size = BATCH_SIZE\n",
        ")\n",
        "# Find how many batch size are there in validation_dataset\n",
        "val_batches = tf.data.experimental.cardinality(validation_dataset)\n",
        "\n",
        "# split dataset into test dataset\n",
        "# then move 20% of them\n",
        "test_dataset = validation_dataset.take(val_batches // 5)\n",
        "validation_dataset = validation_dataset.skip(val_batches // 5)\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_dataset = train_dataset.prefetch(buffer_size= AUTOTUNE)\n",
        "test_dataset = test_dataset.prefetch(buffer_size= AUTOTUNE)\n",
        "validation_dataset = validation_dataset.prefetch(buffer_size= AUTOTUNE)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Beyo6TJd7fB"
      },
      "source": [
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "      input_shape = (IMG_SIZE) + (3,),\n",
        "      include_top = False,\n",
        "      weights = 'imagenet',\n",
        ")\n",
        "\n",
        "base_model.trainable = False"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "472EJ15YaHPX"
      },
      "source": [
        "# Create the model\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "# Data Augmentation & Inputs\n",
        "model.add(tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal',seed = 123, input_shape = (160,160,3))) # Input Layer\n",
        "model.add(tf.keras.layers.experimental.preprocessing.RandomZoom(0.2),)\n",
        "model.add(tf.keras.layers.experimental.preprocessing.Rescaling(1/127.5, offset=-1))\n",
        "\n",
        "model.add(base_model)\n",
        "\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1)) # Prediction layer"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbRdwTgLlDgf",
        "outputId": "8df96d71-bcf0-4448-c194-f4c20202236a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "random_flip_16 (RandomFlip)  (None, 160, 160, 3)       0         \n",
            "_________________________________________________________________\n",
            "random_zoom_11 (RandomZoom)  (None, 160, 160, 3)       0         \n",
            "_________________________________________________________________\n",
            "rescaling_7 (Rescaling)      (None, 160, 160, 3)       0         \n",
            "_________________________________________________________________\n",
            "mobilenetv2_1.00_160 (Functi (None, 5, 5, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 1281      \n",
            "=================================================================\n",
            "Total params: 2,259,265\n",
            "Trainable params: 1,281\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asqCG_C7lO9F",
        "outputId": "f2aeb2a2-5f66-4112-ba8d-81510690f105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "model.fit(train_dataset, epochs= 10, validation_data= validation_dataset)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "63/63 [==============================] - 48s 768ms/step - loss: 0.6388 - accuracy: 0.5990 - val_loss: 0.5324 - val_accuracy: 0.6894\n",
            "Epoch 2/10\n",
            "63/63 [==============================] - 48s 757ms/step - loss: 0.4277 - accuracy: 0.7685 - val_loss: 0.3671 - val_accuracy: 0.8156\n",
            "Epoch 3/10\n",
            "63/63 [==============================] - 48s 766ms/step - loss: 0.3148 - accuracy: 0.8600 - val_loss: 0.2745 - val_accuracy: 0.9022\n",
            "Epoch 4/10\n",
            "63/63 [==============================] - 48s 760ms/step - loss: 0.2474 - accuracy: 0.9030 - val_loss: 0.2237 - val_accuracy: 0.9233\n",
            "Epoch 5/10\n",
            "63/63 [==============================] - 49s 773ms/step - loss: 0.2058 - accuracy: 0.9265 - val_loss: 0.1903 - val_accuracy: 0.9319\n",
            "Epoch 6/10\n",
            "63/63 [==============================] - 49s 770ms/step - loss: 0.1808 - accuracy: 0.9360 - val_loss: 0.1641 - val_accuracy: 0.9431\n",
            "Epoch 7/10\n",
            "63/63 [==============================] - 49s 776ms/step - loss: 0.1579 - accuracy: 0.9455 - val_loss: 0.1398 - val_accuracy: 0.9579\n",
            "Epoch 8/10\n",
            "63/63 [==============================] - 49s 772ms/step - loss: 0.1429 - accuracy: 0.9560 - val_loss: 0.1263 - val_accuracy: 0.9629\n",
            "Epoch 9/10\n",
            "63/63 [==============================] - 48s 768ms/step - loss: 0.1373 - accuracy: 0.9530 - val_loss: 0.1218 - val_accuracy: 0.9604\n",
            "Epoch 10/10\n",
            "63/63 [==============================] - 48s 757ms/step - loss: 0.1259 - accuracy: 0.9560 - val_loss: 0.1116 - val_accuracy: 0.9604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f05594dda20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    }
  ]
}