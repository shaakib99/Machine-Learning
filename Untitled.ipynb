{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    Implementing CNN to flowers dataset\\n    \\n    Learning: \\n        - Overfitting\\n        - How to overcome the problems\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    Implementing CNN to flowers dataset\n",
    "    \n",
    "    Learning: \n",
    "        - Overfitting\n",
    "        - How to overcome the problems\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# CONSTANT\n",
    "FILE_PATH = './datasets/flower_photos/'\n",
    "IMG_SIZE = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(x, class_length):\n",
    "    ohe = [0] * class_length\n",
    "    ohe[x] = 1\n",
    "    \n",
    "    return np.array(ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['daisy','dandelion','roses','sunflowers','tulips']\n",
    "\n",
    "df = []\n",
    "for each_class in classes:\n",
    "    # Find one hot encoding for each class\n",
    "    class_in_one_hot_encoding = one_hot_encoding(classes.index(each_class),len(classes))\n",
    "    \n",
    "    images = glob.glob(FILE_PATH + each_class + '/*.jpg')\n",
    "    \n",
    "    for image in images:\n",
    "        df.append([cv2.resize(cv2.imread(image),(IMG_SIZE,IMG_SIZE)), class_in_one_hot_encoding])\n",
    "        \n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle df\n",
    "random.shuffle(df)\n",
    "\n",
    "# 2500 items for training remaining for test\n",
    "training_set, test_set = df[0:2500], df[2500:]\n",
    "\n",
    "train_x = np.array(list(map(lambda x: x[0], training_set))) / 255\n",
    "train_y = np.array(list(map(lambda x: x[1], training_set)))\n",
    "\n",
    "test_x = np.array(list(map(lambda x: x[0], test_set))) / 255\n",
    "test_y = np.array(list(map(lambda x: x[1], test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "# plt.imshow(train_x[2])\n",
    "model = keras.Sequential()\n",
    "\n",
    "model.add(keras.layers.experimental.preprocessing.RandomFlip('horizontal', input_shape = (IMG_SIZE,IMG_SIZE,3)))\n",
    "model.add(keras.layers.experimental.preprocessing.RandomRotation(0.1))\n",
    "model.add(keras.layers.experimental.preprocessing.RandomZoom(0.1))\n",
    "\n",
    "model.add(keras.layers.Conv2D(96,(3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "\n",
    "model.add(keras.layers.Conv2D(196,(3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Conv2D(196,(3,3), activation='relu'))\n",
    "# model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "\n",
    "\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.BatchNormalization())\n",
    "\n",
    "model.add(keras.layers.Dense(128, activation='relu', kernel_regularizer = 'l2'))\n",
    "\n",
    "model.add(keras.layers.Dense(len(classes), activation = 'softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "79/79 [==============================] - 153s 2s/step - loss: 5.9939 - accuracy: 0.3900 - val_loss: 4.7163 - val_accuracy: 0.3026\n",
      "Epoch 2/200\n",
      "79/79 [==============================] - 152s 2s/step - loss: 3.6668 - accuracy: 0.4728 - val_loss: 3.6610 - val_accuracy: 0.3470\n",
      "Epoch 3/200\n",
      "79/79 [==============================] - 152s 2s/step - loss: 2.7234 - accuracy: 0.5020 - val_loss: 2.5608 - val_accuracy: 0.4915\n",
      "Epoch 4/200\n",
      "79/79 [==============================] - 153s 2s/step - loss: 2.3784 - accuracy: 0.5108 - val_loss: 2.5080 - val_accuracy: 0.4590\n",
      "Epoch 5/200\n",
      "79/79 [==============================] - 153s 2s/step - loss: 2.3751 - accuracy: 0.5296 - val_loss: 2.8872 - val_accuracy: 0.4137\n",
      "Epoch 6/200\n",
      "79/79 [==============================] - 152s 2s/step - loss: 2.4285 - accuracy: 0.5764 - val_loss: 2.7391 - val_accuracy: 0.4795\n",
      "Epoch 7/200\n",
      "79/79 [==============================] - 152s 2s/step - loss: 2.4265 - accuracy: 0.5612 - val_loss: 7.8336 - val_accuracy: 0.2957\n",
      "Epoch 8/200\n",
      "79/79 [==============================] - 154s 2s/step - loss: 2.5188 - accuracy: 0.5648 - val_loss: 3.0882 - val_accuracy: 0.5598\n",
      "Epoch 9/200\n",
      "79/79 [==============================] - 152s 2s/step - loss: 2.3850 - accuracy: 0.5992 - val_loss: 2.6483 - val_accuracy: 0.5752\n",
      "Epoch 10/200\n",
      "79/79 [==============================] - 152s 2s/step - loss: 2.2269 - accuracy: 0.6128 - val_loss: 3.1447 - val_accuracy: 0.4274\n",
      "Epoch 11/200\n",
      "79/79 [==============================] - 153s 2s/step - loss: 2.1267 - accuracy: 0.6208 - val_loss: 2.2228 - val_accuracy: 0.6060\n",
      "Epoch 12/200\n",
      "79/79 [==============================] - 155s 2s/step - loss: 2.0198 - accuracy: 0.6520 - val_loss: 3.9573 - val_accuracy: 0.4675\n",
      "Epoch 13/200\n",
      "79/79 [==============================] - 152s 2s/step - loss: 2.4111 - accuracy: 0.6344 - val_loss: 2.2614 - val_accuracy: 0.6538\n",
      "Epoch 14/200\n",
      "79/79 [==============================] - 152s 2s/step - loss: 2.3208 - accuracy: 0.6420 - val_loss: 3.1878 - val_accuracy: 0.4906\n",
      "Epoch 15/200\n",
      "79/79 [==============================] - 152s 2s/step - loss: 2.3650 - accuracy: 0.6480 - val_loss: 3.6565 - val_accuracy: 0.4419\n",
      "Epoch 16/200\n",
      "79/79 [==============================] - 190s 2s/step - loss: 2.2951 - accuracy: 0.6648 - val_loss: 2.1624 - val_accuracy: 0.6607\n",
      "Epoch 17/200\n",
      "79/79 [==============================] - 192s 2s/step - loss: 1.9654 - accuracy: 0.6736 - val_loss: 2.0726 - val_accuracy: 0.6436\n",
      "Epoch 18/200\n",
      "79/79 [==============================] - 209s 3s/step - loss: 1.9185 - accuracy: 0.6832 - val_loss: 1.9332 - val_accuracy: 0.6786\n",
      "Epoch 19/200\n",
      "79/79 [==============================] - 197s 2s/step - loss: 1.9236 - accuracy: 0.6780 - val_loss: 2.2947 - val_accuracy: 0.5915\n",
      "Epoch 20/200\n",
      "79/79 [==============================] - 182s 2s/step - loss: 2.0550 - accuracy: 0.6844 - val_loss: 2.1687 - val_accuracy: 0.6923\n",
      "Epoch 21/200\n",
      "79/79 [==============================] - 180s 2s/step - loss: 2.0410 - accuracy: 0.6920 - val_loss: 3.0620 - val_accuracy: 0.5983\n",
      "Epoch 22/200\n",
      "79/79 [==============================] - 196s 2s/step - loss: 2.2505 - accuracy: 0.6832 - val_loss: 2.2566 - val_accuracy: 0.6590\n",
      "Epoch 23/200\n",
      "79/79 [==============================] - 174s 2s/step - loss: 2.0622 - accuracy: 0.6912 - val_loss: 2.0122 - val_accuracy: 0.6462\n",
      "Epoch 24/200\n",
      "79/79 [==============================] - 176s 2s/step - loss: 1.8073 - accuracy: 0.7112 - val_loss: 4.3404 - val_accuracy: 0.4829\n",
      "Epoch 25/200\n",
      "79/79 [==============================] - 178s 2s/step - loss: 2.1268 - accuracy: 0.7004 - val_loss: 2.5541 - val_accuracy: 0.6205\n",
      "Epoch 26/200\n",
      "79/79 [==============================] - 177s 2s/step - loss: 2.0341 - accuracy: 0.7112 - val_loss: 2.8696 - val_accuracy: 0.5855\n",
      "Epoch 27/200\n",
      "79/79 [==============================] - 168s 2s/step - loss: 2.0624 - accuracy: 0.7096 - val_loss: 5.4680 - val_accuracy: 0.5778\n",
      "Epoch 28/200\n",
      "79/79 [==============================] - 181s 2s/step - loss: 2.0353 - accuracy: 0.7156 - val_loss: 2.0126 - val_accuracy: 0.6538\n",
      "Epoch 29/200\n",
      "79/79 [==============================] - 181s 2s/step - loss: 1.7269 - accuracy: 0.7160 - val_loss: 1.7344 - val_accuracy: 0.7034\n",
      "Epoch 30/200\n",
      "79/79 [==============================] - 164s 2s/step - loss: 1.8169 - accuracy: 0.7196 - val_loss: 2.4184 - val_accuracy: 0.6538\n",
      "Epoch 31/200\n",
      "79/79 [==============================] - 163s 2s/step - loss: 1.8536 - accuracy: 0.7176 - val_loss: 1.7942 - val_accuracy: 0.7274\n",
      "Epoch 32/200\n",
      "79/79 [==============================] - 176s 2s/step - loss: 1.6650 - accuracy: 0.7192 - val_loss: 1.7836 - val_accuracy: 0.6786\n",
      "Epoch 33/200\n",
      "79/79 [==============================] - 174s 2s/step - loss: 1.6327 - accuracy: 0.7136 - val_loss: 2.5977 - val_accuracy: 0.6120\n",
      "Epoch 34/200\n",
      "79/79 [==============================] - 154s 2s/step - loss: 1.6897 - accuracy: 0.7244 - val_loss: 1.8315 - val_accuracy: 0.6701\n",
      "Epoch 35/200\n",
      "79/79 [==============================] - 154s 2s/step - loss: 1.7845 - accuracy: 0.7276 - val_loss: 1.8238 - val_accuracy: 0.6863\n",
      "Epoch 36/200\n",
      "79/79 [==============================] - 156s 2s/step - loss: 1.6129 - accuracy: 0.7444 - val_loss: 1.6083 - val_accuracy: 0.7077\n",
      "Epoch 37/200\n",
      "79/79 [==============================] - 156s 2s/step - loss: 1.5069 - accuracy: 0.7472 - val_loss: 2.6596 - val_accuracy: 0.5368\n",
      "Epoch 38/200\n",
      "79/79 [==============================] - 154s 2s/step - loss: 1.5618 - accuracy: 0.7412 - val_loss: 1.8327 - val_accuracy: 0.7085\n",
      "Epoch 39/200\n",
      "79/79 [==============================] - 155s 2s/step - loss: 1.6310 - accuracy: 0.7440 - val_loss: 1.6067 - val_accuracy: 0.7231\n",
      "Epoch 40/200\n",
      "79/79 [==============================] - 156s 2s/step - loss: 1.4792 - accuracy: 0.7580 - val_loss: 3.2584 - val_accuracy: 0.4863\n",
      "Epoch 41/200\n",
      "79/79 [==============================] - 155s 2s/step - loss: 1.5542 - accuracy: 0.7308 - val_loss: 1.6034 - val_accuracy: 0.7308\n",
      "Epoch 42/200\n",
      "79/79 [==============================] - 155s 2s/step - loss: 1.5238 - accuracy: 0.7376 - val_loss: 1.5776 - val_accuracy: 0.7214\n",
      "Epoch 43/200\n",
      "79/79 [==============================] - 154s 2s/step - loss: 1.4851 - accuracy: 0.7492 - val_loss: 1.6858 - val_accuracy: 0.7162\n",
      "Epoch 44/200\n",
      "79/79 [==============================] - 156s 2s/step - loss: 1.3865 - accuracy: 0.7668 - val_loss: 1.4728 - val_accuracy: 0.7282\n",
      "Epoch 45/200\n",
      "79/79 [==============================] - 167s 2s/step - loss: 1.5161 - accuracy: 0.7620 - val_loss: 2.0249 - val_accuracy: 0.6709\n",
      "Epoch 46/200\n",
      "79/79 [==============================] - 179s 2s/step - loss: 1.5624 - accuracy: 0.7616 - val_loss: 1.6580 - val_accuracy: 0.7205\n",
      "Epoch 47/200\n",
      "79/79 [==============================] - 155s 2s/step - loss: 1.5775 - accuracy: 0.7572 - val_loss: 2.1129 - val_accuracy: 0.6547\n",
      "Epoch 48/200\n",
      "79/79 [==============================] - 154s 2s/step - loss: 1.6444 - accuracy: 0.7636 - val_loss: 1.7578 - val_accuracy: 0.7214\n",
      "Epoch 49/200\n",
      "79/79 [==============================] - 154s 2s/step - loss: 1.5368 - accuracy: 0.7772 - val_loss: 1.6243 - val_accuracy: 0.7145\n",
      "Epoch 50/200\n",
      "79/79 [==============================] - 154s 2s/step - loss: 1.4091 - accuracy: 0.7656 - val_loss: 1.5099 - val_accuracy: 0.7256\n",
      "Epoch 51/200\n",
      "79/79 [==============================] - 175s 2s/step - loss: 1.4177 - accuracy: 0.7696 - val_loss: 1.8779 - val_accuracy: 0.7077\n",
      "Epoch 52/200\n",
      "79/79 [==============================] - 175s 2s/step - loss: 1.4104 - accuracy: 0.7776 - val_loss: 1.4467 - val_accuracy: 0.7615\n",
      "Epoch 53/200\n",
      "79/79 [==============================] - 189s 2s/step - loss: 1.4118 - accuracy: 0.7852 - val_loss: 1.4966 - val_accuracy: 0.7368\n",
      "Epoch 54/200\n",
      "79/79 [==============================] - 199s 3s/step - loss: 1.3704 - accuracy: 0.7756 - val_loss: 1.6579 - val_accuracy: 0.7171\n",
      "Epoch 55/200\n",
      "79/79 [==============================] - 197s 2s/step - loss: 1.3157 - accuracy: 0.7896 - val_loss: 1.4494 - val_accuracy: 0.7658\n",
      "Epoch 56/200\n",
      "79/79 [==============================] - 185s 2s/step - loss: 1.3820 - accuracy: 0.7836 - val_loss: 1.4840 - val_accuracy: 0.7470\n",
      "Epoch 57/200\n",
      "79/79 [==============================] - 155s 2s/step - loss: 1.3522 - accuracy: 0.7760 - val_loss: 1.5091 - val_accuracy: 0.7333\n",
      "Epoch 58/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 180s 2s/step - loss: 1.4044 - accuracy: 0.7844 - val_loss: 1.4921 - val_accuracy: 0.7590\n",
      "Epoch 59/200\n",
      "79/79 [==============================] - 175s 2s/step - loss: 1.2959 - accuracy: 0.8000 - val_loss: 1.4188 - val_accuracy: 0.7436\n",
      "Epoch 60/200\n",
      "79/79 [==============================] - 154s 2s/step - loss: 1.2420 - accuracy: 0.7984 - val_loss: 1.4295 - val_accuracy: 0.7444\n",
      "Epoch 61/200\n",
      "79/79 [==============================] - 156s 2s/step - loss: 1.4904 - accuracy: 0.7772 - val_loss: 1.6819 - val_accuracy: 0.7077\n",
      "Epoch 62/200\n",
      "79/79 [==============================] - 155s 2s/step - loss: 1.3702 - accuracy: 0.7960 - val_loss: 1.4478 - val_accuracy: 0.7675\n",
      "Epoch 63/200\n",
      "79/79 [==============================] - 154s 2s/step - loss: 1.2324 - accuracy: 0.7980 - val_loss: 1.4177 - val_accuracy: 0.7385\n",
      "Epoch 64/200\n",
      "79/79 [==============================] - 155s 2s/step - loss: 1.3175 - accuracy: 0.7892 - val_loss: 1.4090 - val_accuracy: 0.7692\n",
      "Epoch 65/200\n",
      "79/79 [==============================] - 184s 2s/step - loss: 1.3598 - accuracy: 0.7912 - val_loss: 1.5908 - val_accuracy: 0.7188\n",
      "Epoch 66/200\n",
      "79/79 [==============================] - 195s 2s/step - loss: 1.2248 - accuracy: 0.8112 - val_loss: 1.3160 - val_accuracy: 0.7632\n",
      "Epoch 67/200\n",
      "79/79 [==============================] - 193s 2s/step - loss: 1.2747 - accuracy: 0.7884 - val_loss: 1.4622 - val_accuracy: 0.7393\n",
      "Epoch 68/200\n",
      "79/79 [==============================] - 199s 3s/step - loss: 1.2800 - accuracy: 0.8012 - val_loss: 1.4312 - val_accuracy: 0.7462\n",
      "Epoch 69/200\n",
      "79/79 [==============================] - 194s 2s/step - loss: 1.2885 - accuracy: 0.7884 - val_loss: 1.5899 - val_accuracy: 0.7436\n",
      "Epoch 70/200\n",
      "79/79 [==============================] - 194s 2s/step - loss: 1.2793 - accuracy: 0.7952 - val_loss: 1.4839 - val_accuracy: 0.7598\n",
      "Epoch 71/200\n",
      "79/79 [==============================] - 196s 2s/step - loss: 1.2372 - accuracy: 0.8028 - val_loss: 1.3351 - val_accuracy: 0.7718\n",
      "Epoch 72/200\n",
      "79/79 [==============================] - 199s 3s/step - loss: 1.1501 - accuracy: 0.8192 - val_loss: 2.0225 - val_accuracy: 0.6145\n",
      "Epoch 73/200\n",
      "79/79 [==============================] - 198s 3s/step - loss: 1.2467 - accuracy: 0.8128 - val_loss: 1.4128 - val_accuracy: 0.7615\n",
      "Epoch 74/200\n",
      "79/79 [==============================] - 200s 3s/step - loss: 1.2665 - accuracy: 0.8096 - val_loss: 1.3861 - val_accuracy: 0.7726\n",
      "Epoch 75/200\n",
      "79/79 [==============================] - 181s 2s/step - loss: 1.2466 - accuracy: 0.8216 - val_loss: 1.4850 - val_accuracy: 0.7410\n",
      "Epoch 76/200\n",
      "79/79 [==============================] - 177s 2s/step - loss: 1.1790 - accuracy: 0.8152 - val_loss: 1.3233 - val_accuracy: 0.7778\n",
      "Epoch 77/200\n",
      "79/79 [==============================] - 201s 3s/step - loss: 1.1263 - accuracy: 0.8276 - val_loss: 1.3494 - val_accuracy: 0.7504\n",
      "Epoch 78/200\n",
      "79/79 [==============================] - 177s 2s/step - loss: 1.1812 - accuracy: 0.8204 - val_loss: 1.4896 - val_accuracy: 0.7248\n",
      "Epoch 79/200\n",
      "69/79 [=========================>....] - ETA: 23s - loss: 1.3158 - accuracy: 0.8098"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-3dd82f5328ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "        optimizer='Adam',\n",
    "        loss = 'categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.fit(train_x,train_y, epochs= 200, shuffle=True, validation_data=(test_x,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 20s 540ms/step - loss: 1.7010 - accuracy: 0.7248\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(test_x,test_y)\n",
    "\n",
    "predict = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 23\n",
    "print('Predicted Output::: ',classes[np.argmax(predict[i])], '\\n\\nReal Output:::', classes[np.argmax(test_y[i])])\n",
    "\n",
    "plt.imshow(test_x[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
