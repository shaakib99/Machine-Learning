{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGE_PATH = './datasets/face_detection/'\n",
    "\n",
    "\n",
    "neg = glob.glob(TRAIN_IMAGE_PATH+'neg/*.pgm')\n",
    "pos = glob.glob(TRAIN_IMAGE_PATH+'pos/*.pgm')\n",
    "\n",
    "IMG_SIZE = 35\n",
    "\n",
    "# For training\n",
    "temp_pos = []\n",
    "list(map(lambda x: temp_pos.append([cv2.resize(plt.imread(x),(IMG_SIZE,IMG_SIZE)),[1,0]]), pos[:400]))\n",
    "\n",
    "temp_neg = []\n",
    "list(map(lambda x: temp_neg.append([cv2.resize(plt.imread(x),(IMG_SIZE,IMG_SIZE)), [0,1]]), neg[:400]))\n",
    "\n",
    "train = np.array(temp_pos + temp_neg)\n",
    "\n",
    "# For Test\n",
    "temp_pos = []\n",
    "list(map(lambda x: temp_pos.append(cv2.resize(plt.imread(x),(IMG_SIZE,IMG_SIZE))), pos[100:120]))\n",
    "\n",
    "temp_neg = []\n",
    "list(map(lambda x: temp_neg.append(cv2.resize(plt.imread(x),(IMG_SIZE,IMG_SIZE))), neg[100:120]))\n",
    "\n",
    "test_x = np.array(temp_pos + temp_neg)\n",
    "test_y = np.array([[1,0]]*20 + [[0,1]]*20 )\n",
    "\n",
    "test = test_x,test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling training data\n",
    "np.random.shuffle(train)\n",
    "train_x = []\n",
    "train_y = []\n",
    "for data in train:\n",
    "    train_x.append(data[0])\n",
    "    train_y.append(data[1])\n",
    "train_x = np.array(train_x)\n",
    "train_y = np.array(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.7032 - accuracy: 0.5775\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6501 - accuracy: 0.7088\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6277 - accuracy: 0.7487\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.7950\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5861 - accuracy: 0.7987\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5707 - accuracy: 0.8163\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5560 - accuracy: 0.8087\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5248 - accuracy: 0.8537\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.5211 - accuracy: 0.8400\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8413\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4818 - accuracy: 0.8487\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4724 - accuracy: 0.8512\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.8512\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4355 - accuracy: 0.8662\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4235 - accuracy: 0.8750\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.4116 - accuracy: 0.8775\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4000 - accuracy: 0.8737\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3982 - accuracy: 0.8775\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3870 - accuracy: 0.8950\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4010 - accuracy: 0.8888\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3966 - accuracy: 0.8838\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3841 - accuracy: 0.8963\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3728 - accuracy: 0.8863\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3469 - accuracy: 0.8875\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3441 - accuracy: 0.8913\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3576 - accuracy: 0.9038\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.9050\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3644 - accuracy: 0.8863\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3379 - accuracy: 0.8913\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3373 - accuracy: 0.8888\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3329 - accuracy: 0.8963\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3246 - accuracy: 0.9013\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3564 - accuracy: 0.8988\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3192 - accuracy: 0.8925\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3052 - accuracy: 0.9062\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3325 - accuracy: 0.9013\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3190 - accuracy: 0.9013\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.9137\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3474 - accuracy: 0.8950\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3376 - accuracy: 0.9038\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3432 - accuracy: 0.9013\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3331 - accuracy: 0.9013\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3227 - accuracy: 0.9087\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3220 - accuracy: 0.8975\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3338 - accuracy: 0.8800\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3057 - accuracy: 0.9212\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3241 - accuracy: 0.8988\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3361 - accuracy: 0.8900\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8888\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3322 - accuracy: 0.8913\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3191 - accuracy: 0.9000\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.8950\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3509 - accuracy: 0.8750\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3525 - accuracy: 0.8625\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8850\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3253 - accuracy: 0.9013\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3407 - accuracy: 0.8975\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3628 - accuracy: 0.8612\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3218 - accuracy: 0.8825\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3207 - accuracy: 0.8975\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3271 - accuracy: 0.8938\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3561 - accuracy: 0.8825\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3566 - accuracy: 0.8725\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3228 - accuracy: 0.8988\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3178 - accuracy: 0.9025\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3638 - accuracy: 0.8737\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3649 - accuracy: 0.8813\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3261 - accuracy: 0.9000\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3418 - accuracy: 0.8913\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.9112\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3401 - accuracy: 0.8988\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3225 - accuracy: 0.8913\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3194 - accuracy: 0.8825\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3282 - accuracy: 0.8913\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8988\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3165 - accuracy: 0.8963\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2888 - accuracy: 0.9087\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2858 - accuracy: 0.9175\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3195 - accuracy: 0.8900\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3764 - accuracy: 0.8425\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3701 - accuracy: 0.8700\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3529 - accuracy: 0.8838\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3890 - accuracy: 0.8413\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3751 - accuracy: 0.8737\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3997 - accuracy: 0.8750\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3686 - accuracy: 0.8838\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.4008 - accuracy: 0.8425\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3644 - accuracy: 0.8863\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3289 - accuracy: 0.9013\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3527 - accuracy: 0.8925\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.2964 - accuracy: 0.9187\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.3435 - accuracy: 0.8775\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3251 - accuracy: 0.9087\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2990 - accuracy: 0.8925\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3215 - accuracy: 0.9062\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3681 - accuracy: 0.8625\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3388 - accuracy: 0.8775\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3364 - accuracy: 0.8925\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.3357 - accuracy: 0.8825\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.2949 - accuracy: 0.9112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1688156a0>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(IMG_SIZE,IMG_SIZE)),\n",
    "    keras.layers.Dense(128,activation='sigmoid'),\n",
    "    keras.layers.Dense(128,activation='sigmoid'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='SGD',\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# model.summary()\n",
    "model.fit(train_x,train_y, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x168a8fca0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Predicted:  0 Real Output:  0 Index:  0 Real Value:  [0.61502784 0.38497216]\n",
      "Predicted:  0 Real Output:  0 Index:  1 Real Value:  [0.7296651  0.27033493]\n",
      "Predicted:  0 Real Output:  0 Index:  2 Real Value:  [0.8119826  0.18801741]\n",
      "Predicted:  0 Real Output:  0 Index:  3 Real Value:  [0.53209823 0.4679018 ]\n",
      "Predicted:  0 Real Output:  0 Index:  4 Real Value:  [0.9061909  0.09380909]\n",
      "Predicted:  0 Real Output:  0 Index:  5 Real Value:  [0.83218867 0.1678113 ]\n",
      "Predicted:  0 Real Output:  0 Index:  6 Real Value:  [0.90592057 0.09407945]\n",
      "Predicted:  0 Real Output:  0 Index:  7 Real Value:  [0.7507996  0.24920039]\n",
      "Predicted:  0 Real Output:  0 Index:  8 Real Value:  [0.8489711  0.15102889]\n",
      "Predicted:  0 Real Output:  0 Index:  9 Real Value:  [0.8871044  0.11289558]\n",
      "Predicted:  0 Real Output:  0 Index:  10 Real Value:  [0.8517328  0.14826718]\n",
      "Predicted:  0 Real Output:  0 Index:  11 Real Value:  [0.83069456 0.16930541]\n",
      "Predicted:  0 Real Output:  0 Index:  12 Real Value:  [0.90620744 0.09379262]\n",
      "Predicted:  0 Real Output:  0 Index:  13 Real Value:  [0.84895897 0.15104097]\n",
      "Predicted:  0 Real Output:  0 Index:  14 Real Value:  [0.5320983  0.46790177]\n",
      "Predicted:  0 Real Output:  0 Index:  15 Real Value:  [0.5321523  0.46784773]\n",
      "Predicted:  0 Real Output:  0 Index:  16 Real Value:  [0.53209823 0.4679018 ]\n",
      "Predicted:  0 Real Output:  0 Index:  17 Real Value:  [0.53124076 0.4687592 ]\n",
      "Predicted:  0 Real Output:  0 Index:  18 Real Value:  [0.5319245  0.46807554]\n",
      "Predicted:  1 Real Output:  0 Index:  19 Real Value:  [0.47920734 0.52079266]\n",
      "Predicted:  1 Real Output:  1 Index:  20 Real Value:  [0.28034818 0.71965176]\n",
      "Predicted:  1 Real Output:  1 Index:  21 Real Value:  [0.03485228 0.9651477 ]\n",
      "Predicted:  0 Real Output:  1 Index:  22 Real Value:  [0.53209823 0.4679018 ]\n",
      "Predicted:  1 Real Output:  1 Index:  23 Real Value:  [0.13454181 0.86545825]\n",
      "Predicted:  1 Real Output:  1 Index:  24 Real Value:  [0.32356247 0.67643756]\n",
      "Predicted:  1 Real Output:  1 Index:  25 Real Value:  [0.01955417 0.9804458 ]\n",
      "Predicted:  1 Real Output:  1 Index:  26 Real Value:  [0.37080875 0.6291912 ]\n",
      "Predicted:  1 Real Output:  1 Index:  27 Real Value:  [0.03628791 0.9637121 ]\n",
      "Predicted:  1 Real Output:  1 Index:  28 Real Value:  [0.12588283 0.8741172 ]\n",
      "Predicted:  1 Real Output:  1 Index:  29 Real Value:  [0.18736026 0.8126398 ]\n",
      "Predicted:  1 Real Output:  1 Index:  30 Real Value:  [0.32356125 0.67643875]\n",
      "Predicted:  1 Real Output:  1 Index:  31 Real Value:  [0.02141498 0.978585  ]\n",
      "Predicted:  1 Real Output:  1 Index:  32 Real Value:  [0.14270659 0.85729337]\n",
      "Predicted:  1 Real Output:  1 Index:  33 Real Value:  [0.13517936 0.86482066]\n",
      "Predicted:  1 Real Output:  1 Index:  34 Real Value:  [0.37080908 0.62919086]\n",
      "Predicted:  1 Real Output:  1 Index:  35 Real Value:  [0.07657307 0.9234269 ]\n",
      "Predicted:  1 Real Output:  1 Index:  36 Real Value:  [0.32356653 0.6764335 ]\n",
      "Predicted:  1 Real Output:  1 Index:  37 Real Value:  [0.13454174 0.86545825]\n",
      "Predicted:  1 Real Output:  1 Index:  38 Real Value:  [0.4133248  0.58667517]\n",
      "Predicted:  1 Real Output:  1 Index:  39 Real Value:  [0.3797099  0.62029004]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = model.predict(test[0])\n",
    "plt.imshow(test[0][39], cmap='gray')\n",
    "i = 0\n",
    "for each_x in x:\n",
    "    print(\"Predicted: \",np.argmax(each_x), \"Real Output: \",np.argmax(test[1][i]), \"Index: \",i, \"Real Value: \", each_x)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
